# Databricks notebook source
import numpy as np
import pandas as pd

from pyspark import SparkFiles
from pyspark import SparkContext
from pyspark.sql import functions
import pyspark.sql.functions #import avg, col, udf
from pyspark.sql import SQLContext
from pyspark.sql import DataFrame
from pyspark.sql.types import *
import json

AAL_30min_spark_DF_newRow = StructType([StructField("AAL_date/time", StringType(), True),StructField("AAL_adjOpen", FloatType(), True),StructField("AAL_adjHigh", FloatType(), True),StructField("AAL_adjLow", FloatType(), True),StructField("AAL_adjClose", FloatType(), True),StructField("AAL_adjVolume", IntegerType(), True)])
AAL_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AAL_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AAL_30min.txt")
display(AAL_30min_spark_DF)

AAPL_30min_spark_DF_newRow = StructType([StructField("AAPL_date/time", StringType(), True),StructField("AAPL_adjOpen", FloatType(), True),StructField("AAPL_adjHigh", FloatType(), True),StructField("AAPL_adjLow", FloatType(), True),StructField("AAPL_adjClose", FloatType(), True),StructField("AAPL_adjVolume", IntegerType(), True)])
AAPL_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AAPL_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AAPL_30min.txt")
display(AAPL_30min_spark_DF)

AAP_30min_spark_DF_newRow = StructType([StructField("AAP_date/time", StringType(), True),StructField("AAP_adjOpen", FloatType(), True),StructField("AAP_adjHigh", FloatType(), True),StructField("AAP_adjLow", FloatType(), True),StructField("AAP_adjClose", FloatType(), True),StructField("AAP_adjVolume", IntegerType(), True)])
AAP_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AAP_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AAP_30min.txt")
display(AAP_30min_spark_DF)

AA_30min_spark_DF_newRow = StructType([StructField("AA_date/time", StringType(), True),StructField("AA_adjOpen", FloatType(), True),StructField("AA_adjHigh", FloatType(), True),StructField("AA_adjLow", FloatType(), True),StructField("AA_adjClose", FloatType(), True),StructField("AA_adjVolume", IntegerType(), True)])
AA_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AA_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AA_30min.txt")
display(AA_30min_spark_DF)

ABBV_30min_spark_DF_newRow = StructType([StructField("ABBV_date/time", StringType(), True),StructField("ABBV_adjOpen", FloatType(), True),StructField("ABBV_adjHigh", FloatType(), True),StructField("ABBV_adjLow", FloatType(), True),StructField("ABBV_adjClose", FloatType(), True),StructField("ABBV_adjVolume", IntegerType(), True)])
ABBV_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ABBV_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ABBV_30min.txt")
display(ABBV_30min_spark_DF)

ABC_30min_spark_DF_newRow = StructType([StructField("ABC_date/time", StringType(), True),StructField("ABC_adjOpen", FloatType(), True),StructField("ABC_adjHigh", FloatType(), True),StructField("ABC_adjLow", FloatType(), True),StructField("ABC_adjClose", FloatType(), True),StructField("ABC_adjVolume", IntegerType(), True)])
ABC_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ABC_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ABC_30min.txt")
display(ABC_30min_spark_DF)

ABMD_30min_spark_DF_newRow = StructType([StructField("ABMD_date/time", StringType(), True),StructField("ABMD_adjOpen", FloatType(), True),StructField("ABMD_adjHigh", FloatType(), True),StructField("ABMD_adjLow", FloatType(), True),StructField("ABMD_adjClose", FloatType(), True),StructField("ABMD_adjVolume", IntegerType(), True)])
ABMD_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ABMD_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ABMD_30min.txt")
display(ABMD_30min_spark_DF)

ABMD_30min_spark_DF_newRow = StructType([StructField("ABMD_date/time", StringType(), True),StructField("ABMD_adjOpen", FloatType(), True),StructField("ABMD_adjHigh", FloatType(), True),StructField("ABMD_adjLow", FloatType(), True),StructField("ABMD_adjClose", FloatType(), True),StructField("ABMD_adjVolume", IntegerType(), True)])
ABMD_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ABMD_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ABMD_30min.txt")
display(ABMD_30min_spark_DF)

ABT_30min_spark_DF_newRow = StructType([StructField("ABT_date/time", StringType(), True),StructField("ABT_adjOpen", FloatType(), True),StructField("ABT_adjHigh", FloatType(), True),StructField("ABT_adjLow", FloatType(), True),StructField("ABT_adjClose", FloatType(), True),StructField("ABT_adjVolume", IntegerType(), True)])
ABT_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ABT_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ABT_30min.txt")
display(ABT_30min_spark_DF)

ACN_30min_spark_DF_newRow = StructType([StructField("ACN_date/time", StringType(), True),StructField("ACN_adjOpen", FloatType(), True),StructField("ACN_adjHigh", FloatType(), True),StructField("ACN_adjLow", FloatType(), True),StructField("ACN_adjClose", FloatType(), True),StructField("ACN_adjVolume", IntegerType(), True)])
ACN_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ACN_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ACN_30min.txt")
display(ACN_30min_spark_DF)

ACV_30min_spark_DF_newRow = StructType([StructField("ACV_date/time", StringType(), True),StructField("ACV_adjOpen", FloatType(), True),StructField("ACV_adjHigh", FloatType(), True),StructField("ACV_adjLow", FloatType(), True),StructField("ACV_adjClose", FloatType(), True),StructField("ACV_adjVolume", IntegerType(), True)])
ACV_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ACV_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ACV_30min.txt")
display(ACV_30min_spark_DF)

ADBE_30min_spark_DF_newRow = StructType([StructField("ADBE_date/time", StringType(), True),StructField("ADBE_adjOpen", FloatType(), True),StructField("ADBE_adjHigh", FloatType(), True),StructField("ADBE_adjLow", FloatType(), True),StructField("ADBE_adjClose", FloatType(), True),StructField("ADBE_adjVolume", IntegerType(), True)])
ADBE_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ADBE_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ADBE_30min.txt")
display(ADBE_30min_spark_DF)

ADI_30min_spark_DF_newRow = StructType([StructField("ADI_date/time", StringType(), True),StructField("ADI_adjOpen", FloatType(), True),StructField("ADI_adjHigh", FloatType(), True),StructField("ADI_adjLow", FloatType(), True),StructField("ADI_adjClose", FloatType(), True),StructField("ADI_adjVolume", IntegerType(), True)])
ADI_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ADI_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ADI_30min.txt")
display(ADI_30min_spark_DF)

ADM_30min_spark_DF_newRow = StructType([StructField("ADM_date/time", StringType(), True),StructField("ADM_adjOpen", FloatType(), True),StructField("ADM_adjHigh", FloatType(), True),StructField("ADM_adjLow", FloatType(), True),StructField("ADM_adjClose", FloatType(), True),StructField("ADM_adjVolume", IntegerType(), True)])
ADM_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ADM_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ADM_30min.txt")
display(ADM_30min_spark_DF)

ADP_30min_spark_DF_newRow = StructType([StructField("ADP_date/time", StringType(), True),StructField("ADP_adjOpen", FloatType(), True),StructField("ADP_adjHigh", FloatType(), True),StructField("ADP_adjLow", FloatType(), True),StructField("ADP_adjClose", FloatType(), True),StructField("ADP_adjVolume", IntegerType(), True)])
ADP_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ADP_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ADP_30min.txt")
display(ADP_30min_spark_DF)

ADSK_30min_spark_DF_newRow = StructType([StructField("ADSK_date/time", StringType(), True),StructField("ADSK_adjOpen", FloatType(), True),StructField("ADSK_adjHigh", FloatType(), True),StructField("ADSK_adjLow", FloatType(), True),StructField("ADSK_adjClose", FloatType(), True),StructField("ADSK_adjVolume", IntegerType(), True)])
ADSK_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ADSK_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ADSK_30min.txt")
display(ADSK_30min_spark_DF)

ADS_30min_spark_DF_newRow = StructType([StructField("ADS_date/time", StringType(), True),StructField("ADS_adjOpen", FloatType(), True),StructField("ADS_adjHigh", FloatType(), True),StructField("ADS_adjLow", FloatType(), True),StructField("ADS_adjClose", FloatType(), True),StructField("ADS_adjVolume", IntegerType(), True)])
ADS_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ADS_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ADS_30min.txt")
display(ADS_30min_spark_DF)

ADT_30min_spark_DF_newRow = StructType([StructField("ADT_date/time", StringType(), True),StructField("ADT_adjOpen", FloatType(), True),StructField("ADT_adjHigh", FloatType(), True),StructField("ADT_adjLow", FloatType(), True),StructField("ADT_adjClose", FloatType(), True),StructField("ADT_adjVolume", IntegerType(), True)])
ADT_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ADT_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ADT_30min.txt")
display(ADT_30min_spark_DF)

AEE_30min_spark_DF_newRow = StructType([StructField("AEE_date/time", StringType(), True),StructField("AEE_adjOpen", FloatType(), True),StructField("AEE_adjHigh", FloatType(), True),StructField("AEE_adjLow", FloatType(), True),StructField("AEE_adjClose", FloatType(), True),StructField("AEE_adjVolume", IntegerType(), True)])
AEE_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AEE_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AEE_30min.txt")
display(AEE_30min_spark_DF)

AEP_30min_spark_DF_newRow = StructType([StructField("AEP_date/time", StringType(), True),StructField("AEP_adjOpen", FloatType(), True),StructField("AEP_adjHigh", FloatType(), True),StructField("AEP_adjLow", FloatType(), True),StructField("AEP_adjClose", FloatType(), True),StructField("AEP_adjVolume", IntegerType(), True)])
AEP_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AEP_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AEP_30min.txt")
display(AEP_30min_spark_DF)

AES_30min_spark_DF_newRow = StructType([StructField("AES_date/time", StringType(), True),StructField("AES_adjOpen", FloatType(), True),StructField("AES_adjHigh", FloatType(), True),StructField("AES_adjLow", FloatType(), True),StructField("AES_adjClose", FloatType(), True),StructField("AES_adjVolume", IntegerType(), True)])
AES_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AES_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AES_30min.txt")
display(AES_30min_spark_DF)

AFL_30min_spark_DF_newRow = StructType([StructField("AFL_date/time", StringType(), True),StructField("AFL_adjOpen", FloatType(), True),StructField("AFL_adjHigh", FloatType(), True),StructField("AFL_adjLow", FloatType(), True),StructField("AFL_adjClose", FloatType(), True),StructField("AFL_adjVolume", IntegerType(), True)])
AFL_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AFL_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AFL_30min.txt")
display(AFL_30min_spark_DF)

AIG_30min_spark_DF_newRow = StructType([StructField("AIG_date/time", StringType(), True),StructField("AIG_adjOpen", FloatType(), True),StructField("AIG_adjHigh", FloatType(), True),StructField("AIG_adjLow", FloatType(), True),StructField("AIG_adjClose", FloatType(), True),StructField("AIG_adjVolume", IntegerType(), True)])
AIG_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AIG_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AIG_30min.txt")
display(AIG_30min_spark_DF)

AINV_30min_spark_DF_newRow = StructType([StructField("AINV_date/time", StringType(), True),StructField("AINV_adjOpen", FloatType(), True),StructField("AINV_adjHigh", FloatType(), True),StructField("AINV_adjLow", FloatType(), True),StructField("AINV_adjClose", FloatType(), True),StructField("AINV_adjVolume", IntegerType(), True)])
AINV_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AINV_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AINV_30min.txt")
display(AINV_30min_spark_DF)

AIV_30min_spark_DF_newRow = StructType([StructField("AIV_date/time", StringType(), True),StructField("AIV_adjOpen", FloatType(), True),StructField("AIV_adjHigh", FloatType(), True),StructField("AIV_adjLow", FloatType(), True),StructField("AIV_adjClose", FloatType(), True),StructField("AIV_adjVolume", IntegerType(), True)])
AIV_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AIV_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AIV_30min.txt")
display(AIV_30min_spark_DF)

AIZ_30min_spark_DF_newRow = StructType([StructField("AIZ_date/time", StringType(), True),StructField("AIZ_adjOpen", FloatType(), True),StructField("AIZ_adjHigh", FloatType(), True),StructField("AIZ_adjLow", FloatType(), True),StructField("AIZ_adjClose", FloatType(), True),StructField("AIZ_adjVolume", IntegerType(), True)])
AIZ_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AIZ_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AIZ_30min.txt")
display(AIZ_30min_spark_DF)

AJG_30min_spark_DF_newRow = StructType([StructField("AJG_date/time", StringType(), True),StructField("AJG_adjOpen", FloatType(), True),StructField("AJG_adjHigh", FloatType(), True),StructField("AJG_adjLow", FloatType(), True),StructField("AJG_adjClose", FloatType(), True),StructField("AJG_adjVolume", IntegerType(), True)])
AJG_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AJG_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AJG_30min.txt")
display(AJG_30min_spark_DF)

AKAM_30min_spark_DF_newRow = StructType([StructField("AKAM_date/time", StringType(), True),StructField("AKAM_adjOpen", FloatType(), True),StructField("AKAM_adjHigh", FloatType(), True),StructField("AKAM_adjLow", FloatType(), True),StructField("AKAM_adjClose", FloatType(), True),StructField("AKAM_adjVolume", IntegerType(), True)])
AKAM_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AKAM_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AKAM_30min.txt")
display(AKAM_30min_spark_DF)

ALB_30min_spark_DF_newRow = StructType([StructField("ALB_date/time", StringType(), True),StructField("ALB_adjOpen", FloatType(), True),StructField("ALB_adjHigh", FloatType(), True),StructField("ALB_adjLow", FloatType(), True),StructField("ALB_adjClose", FloatType(), True),StructField("ALB_adjVolume", IntegerType(), True)])
ALB_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ALB_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ALB_30min.txt")
display(ALB_30min_spark_DF)

ALGN_30min_spark_DF_newRow = StructType([StructField("ALGN_date/time", StringType(), True),StructField("ALGN_adjOpen", FloatType(), True),StructField("ALGN_adjHigh", FloatType(), True),StructField("ALGN_adjLow", FloatType(), True),StructField("ALGN_adjClose", FloatType(), True),StructField("ALGN_adjVolume", IntegerType(), True)])
ALGN_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ALGN_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ALGN_30min.txt")
display(ALGN_30min_spark_DF)

ALK_30min_spark_DF_newRow = StructType([StructField("ALK_date/time", StringType(), True),StructField("ALK_adjOpen", FloatType(), True),StructField("ALK_adjHigh", FloatType(), True),StructField("ALK_adjLow", FloatType(), True),StructField("ALK_adjClose", FloatType(), True),StructField("ALK_adjVolume", IntegerType(), True)])
ALK_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ALK_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ALK_30min.txt")
display(ALK_30min_spark_DF)

ALLE_30min_spark_DF_newRow = StructType([StructField("ALLE_date/time", StringType(), True),StructField("ALLE_adjOpen", FloatType(), True),StructField("ALLE_adjHigh", FloatType(), True),StructField("ALLE_adjLow", FloatType(), True),StructField("ALLE_adjClose", FloatType(), True),StructField("ALLE_adjVolume", IntegerType(), True)])
ALLE_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ALLE_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ALLE_30min.txt")
display(ALLE_30min_spark_DF)

ALL_30min_spark_DF_newRow = StructType([StructField("ALL_date/time", StringType(), True),StructField("ALL_adjOpen", FloatType(), True),StructField("ALL_adjHigh", FloatType(), True),StructField("ALL_adjLow", FloatType(), True),StructField("ALL_adjClose", FloatType(), True),StructField("ALL_adjVolume", IntegerType(), True)])
ALL_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ALL_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ALL_30min.txt")
display(ALL_30min_spark_DF)

ALTR_30min_spark_DF_newRow = StructType([StructField("ALTR_date/time", StringType(), True),StructField("ALTR_adjOpen", FloatType(), True),StructField("ALTR_adjHigh", FloatType(), True),StructField("ALTR_adjLow", FloatType(), True),StructField("ALTR_adjClose", FloatType(), True),StructField("ALTR_adjVolume", IntegerType(), True)])
ALTR_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ALTR_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ALTR_30min.txt")
display(ALTR_30min_spark_DF)

AMAT_30min_spark_DF_newRow = StructType([StructField("AMAT_date/time", StringType(), True),StructField("AMAT_adjOpen", FloatType(), True),StructField("AMAT_adjHigh", FloatType(), True),StructField("AMAT_adjLow", FloatType(), True),StructField("AMAT_adjClose", FloatType(), True),StructField("AMAT_adjVolume", IntegerType(), True)])
AMAT_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AMAT_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AMAT_30min.txt")
display(AMAT_30min_spark_DF)

AMBC_30min_spark_DF_newRow = StructType([StructField("AMBC_date/time", StringType(), True),StructField("AMBC_adjOpen", FloatType(), True),StructField("AMBC_adjHigh", FloatType(), True),StructField("AMBC_adjLow", FloatType(), True),StructField("AMBC_adjClose", FloatType(), True),StructField("AMBC_adjVolume", IntegerType(), True)])
AMBC_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AMBC_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AMBC_30min.txt")
display(AMBC_30min_spark_DF)

AMCR_30min_spark_DF_newRow = StructType([StructField("AMCR_date/time", StringType(), True),StructField("AMCR_adjOpen", FloatType(), True),StructField("AMCR_adjHigh", FloatType(), True),StructField("AMCR_adjLow", FloatType(), True),StructField("AMCR_adjClose", FloatType(), True),StructField("AMCR_adjVolume", IntegerType(), True)])
AMCR_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AMCR_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AMCR_30min.txt")
display(AMCR_30min_spark_DF)

AMD_30min_spark_DF_newRow = StructType([StructField("AMD_date/time", StringType(), True),StructField("AMD_adjOpen", FloatType(), True),StructField("AMD_adjHigh", FloatType(), True),StructField("AMD_adjLow", FloatType(), True),StructField("AMD_adjClose", FloatType(), True),StructField("AMD_adjVolume", IntegerType(), True)])
AMD_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AMD_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AMD_30min.txt")
display(AMD_30min_spark_DF)

AME_30min_spark_DF_newRow = StructType([StructField("AME_date/time", StringType(), True),StructField("AME_adjOpen", FloatType(), True),StructField("AME_adjHigh", FloatType(), True),StructField("AME_adjLow", FloatType(), True),StructField("AME_adjClose", FloatType(), True),StructField("AME_adjVolume", IntegerType(), True)])
AME_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AME_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AME_30min.txt")
display(AME_30min_spark_DF)

AMGN_30min_spark_DF_newRow = StructType([StructField("AMGN_date/time", StringType(), True),StructField("AMGN_adjOpen", FloatType(), True),StructField("AMGN_adjHigh", FloatType(), True),StructField("AMGN_adjLow", FloatType(), True),StructField("AMGN_adjClose", FloatType(), True),StructField("AMGN_adjVolume", IntegerType(), True)])
AMGN_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AMGN_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AMGN_30min.txt")
display(AMGN_30min_spark_DF)

AMG_30min_spark_DF_newRow = StructType([StructField("AMG_date/time", StringType(), True),StructField("AMG_adjOpen", FloatType(), True),StructField("AMG_adjHigh", FloatType(), True),StructField("AMG_adjLow", FloatType(), True),StructField("AMG_adjClose", FloatType(), True),StructField("AMG_adjVolume", IntegerType(), True)])
AMG_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AMG_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AMG_30min.txt")
display(AMG_30min_spark_DF)

AMP_30min_spark_DF_newRow = StructType([StructField("AMP_date/time", StringType(), True),StructField("AMP_adjOpen", FloatType(), True),StructField("AMP_adjHigh", FloatType(), True),StructField("AMP_adjLow", FloatType(), True),StructField("AMP_adjClose", FloatType(), True),StructField("AMP_adjVolume", IntegerType(), True)])
AMP_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AMP_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AMP_30min.txt")
display(AMP_30min_spark_DF)

AMT_30min_spark_DF_newRow = StructType([StructField("AMT_date/time", StringType(), True),StructField("AMT_adjOpen", FloatType(), True),StructField("AMT_adjHigh", FloatType(), True),StructField("AMT_adjLow", FloatType(), True),StructField("AMT_adjClose", FloatType(), True),StructField("AMT_adjVolume", IntegerType(), True)])
AMT_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AMT_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AMT_30min.txt")
display(AMT_30min_spark_DF)

AMZN_30min_spark_DF_newRow = StructType([StructField("AMZN_date/time", StringType(), True),StructField("AMZN_adjOpen", FloatType(), True),StructField("AMZN_adjHigh", FloatType(), True),StructField("AMZN_adjLow", FloatType(), True),StructField("AMZN_adjClose", FloatType(), True),StructField("AMZN_adjVolume", IntegerType(), True)])
AMZN_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AMZN_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AMZN_30min.txt")
display(AMZN_30min_spark_DF)

ANET_30min_spark_DF_newRow = StructType([StructField("ANET_date/time", StringType(), True),StructField("ANET_adjOpen", FloatType(), True),StructField("ANET_adjHigh", FloatType(), True),StructField("ANET_adjLow", FloatType(), True),StructField("ANET_adjClose", FloatType(), True),StructField("ANET_adjVolume", IntegerType(), True)])
ANET_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ANET_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ANET_30min.txt")
display(ANET_30min_spark_DF)

ANF_30min_spark_DF_newRow = StructType([StructField("ANF_date/time", StringType(), True),StructField("ANF_adjOpen", FloatType(), True),StructField("ANF_adjHigh", FloatType(), True),StructField("ANF_adjLow", FloatType(), True),StructField("ANF_adjClose", FloatType(), True),StructField("ANF_adjVolume", IntegerType(), True)])
ANF_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ANF_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ANF_30min.txt")
display(ANF_30min_spark_DF)

ANSS_30min_spark_DF_newRow = StructType([StructField("ANSS_date/time", StringType(), True),StructField("ANSS_adjOpen", FloatType(), True),StructField("ANSS_adjHigh", FloatType(), True),StructField("ANSS_adjLow", FloatType(), True),StructField("ANSS_adjClose", FloatType(), True),StructField("ANSS_adjVolume", IntegerType(), True)])
ANSS_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ANSS_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ANSS_30min.txt")
display(ANSS_30min_spark_DF)

ANTM_30min_spark_DF_newRow = StructType([StructField("ANTM_date/time", StringType(), True),StructField("ANTM_adjOpen", FloatType(), True),StructField("ANTM_adjHigh", FloatType(), True),StructField("ANTM_adjLow", FloatType(), True),StructField("ANTM_adjClose", FloatType(), True),StructField("ANTM_adjVolume", IntegerType(), True)])
ANTM_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ANTM_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ANTM_30min.txt")
display(ANTM_30min_spark_DF)

AN_30min_spark_DF_newRow = StructType([StructField("AN_date/time", StringType(), True),StructField("AN_adjOpen", FloatType(), True),StructField("AN_adjHigh", FloatType(), True),StructField("AN_adjLow", FloatType(), True),StructField("AN_adjClose", FloatType(), True),StructField("AN_adjVolume", IntegerType(), True)])
AN_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AN_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AN_30min.txt")
display(AN_30min_spark_DF)

AON_30min_spark_DF_newRow = StructType([StructField("AON_date/time", StringType(), True),StructField("AON_adjOpen", FloatType(), True),StructField("AON_adjHigh", FloatType(), True),StructField("AON_adjLow", FloatType(), True),StructField("AON_adjClose", FloatType(), True),StructField("AON_adjVolume", IntegerType(), True)])
AON_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AON_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AON_30min.txt")
display(AON_30min_spark_DF)

AOS_30min_spark_DF_newRow = StructType([StructField("AOS_date/time", StringType(), True),StructField("AOS_adjOpen", FloatType(), True),StructField("AOS_adjHigh", FloatType(), True),StructField("AOS_adjLow", FloatType(), True),StructField("AOS_adjClose", FloatType(), True),StructField("AOS_adjVolume", IntegerType(), True)])
AOS_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AOS_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AOS_30min.txt")
display(AOS_30min_spark_DF)

APA_30min_spark_DF_newRow = StructType([StructField("APA_date/time", StringType(), True),StructField("APA_adjOpen", FloatType(), True),StructField("APA_adjHigh", FloatType(), True),StructField("APA_adjLow", FloatType(), True),StructField("APA_adjClose", FloatType(), True),StructField("APA_adjVolume", IntegerType(), True)])
APA_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(APA_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/APA_30min.txt")
display(APA_30min_spark_DF)

APD_30min_spark_DF_newRow = StructType([StructField("APD_date/time", StringType(), True),StructField("APD_adjOpen", FloatType(), True),StructField("APD_adjHigh", FloatType(), True),StructField("APD_adjLow", FloatType(), True),StructField("APD_adjClose", FloatType(), True),StructField("APD_adjVolume", IntegerType(), True)])
APD_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(APA_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/APD_30min.txt")
display(APD_30min_spark_DF)

APH_30min_spark_DF_newRow = StructType([StructField("APH_date/time", StringType(), True),StructField("APH_adjOpen", FloatType(), True),StructField("APH_adjHigh", FloatType(), True),StructField("APH_adjLow", FloatType(), True),StructField("APH_adjClose", FloatType(), True),StructField("APH_adjVolume", IntegerType(), True)])
APH_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(APH_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/APH_30min.txt")
display(APH_30min_spark_DF)

APTV_30min_spark_DF_newRow = StructType([StructField("APTV_date/time", StringType(), True),StructField("APTV_adjOpen", FloatType(), True),StructField("APTV_adjHigh", FloatType(), True),StructField("APTV_adjLow", FloatType(), True),StructField("APTV_adjClose", FloatType(), True),StructField("APTV_adjVolume", IntegerType(), True)])
APTV_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(APTV_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/APTV_30min.txt")
display(APTV_30min_spark_DF)

APTV_30min_spark_DF_newRow = StructType([StructField("APTV_date/time", StringType(), True),StructField("APTV_adjOpen", FloatType(), True),StructField("APTV_adjHigh", FloatType(), True),StructField("APTV_adjLow", FloatType(), True),StructField("APTV_adjClose", FloatType(), True),StructField("APTV_adjVolume", IntegerType(), True)])
APTV_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(APTV_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/APTV_30min.txt")
display(APTV_30min_spark_DF)

ARNC_30min_spark_DF_newRow = StructType([StructField("ARNC_date/time", StringType(), True),StructField("ARNC_adjOpen", FloatType(), True),StructField("ARNC_adjHigh", FloatType(), True),StructField("ARNC_adjLow", FloatType(), True),StructField("ARNC_adjClose", FloatType(), True),StructField("ARNC_adjVolume", IntegerType(), True)])
ARNC_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ARNC_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ARNC_30min.txt")
display(ARNC_30min_spark_DF)

ASH_30min_spark_DF_newRow = StructType([StructField("ASH_date/time", StringType(), True),StructField("ASH_adjOpen", FloatType(), True),StructField("ASH_adjHigh", FloatType(), True),StructField("ASH_adjLow", FloatType(), True),StructField("ASH_adjClose", FloatType(), True),StructField("ASH_adjVolume", IntegerType(), True)])
ASH_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ASH_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ASH_30min.txt")
display(ASH_30min_spark_DF)

ASO_30min_spark_DF_newRow = StructType([StructField("ASO_date/time", StringType(), True),StructField("ASO_adjOpen", FloatType(), True),StructField("ASO_adjHigh", FloatType(), True),StructField("ASO_adjLow", FloatType(), True),StructField("ASO_adjClose", FloatType(), True),StructField("ASO_adjVolume", IntegerType(), True)])
ASO_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ASO_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ASO_30min.txt")
display(ASO_30min_spark_DF)

ATGE_30min_spark_DF_newRow = StructType([StructField("ATGE_date/time", StringType(), True),StructField("ATGE_adjOpen", FloatType(), True),StructField("ATGE_adjHigh", FloatType(), True),StructField("ATGE_adjLow", FloatType(), True),StructField("ATGE_adjClose", FloatType(), True),StructField("ATGE_adjVolume", IntegerType(), True)])
ATGE_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ATGE_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ATGE_30min.txt")
display(ATGE_30min_spark_DF)

ATI_30min_spark_DF_newRow = StructType([StructField("ATI_date/time", StringType(), True),StructField("ATI_adjOpen", FloatType(), True),StructField("ATI_adjHigh", FloatType(), True),StructField("ATI_adjLow", FloatType(), True),StructField("ATI_adjClose", FloatType(), True),StructField("ATI_adjVolume", IntegerType(), True)])
ATI_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ATI_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ATI_30min.txt")
display(ATI_30min_spark_DF)

ATO_30min_spark_DF_newRow = StructType([StructField("ATO_date/time", StringType(), True),StructField("ATO_adjOpen", FloatType(), True),StructField("ATO_adjHigh", FloatType(), True),StructField("ATO_adjLow", FloatType(), True),StructField("ATO_adjClose", FloatType(), True),StructField("ATO_adjVolume", IntegerType(), True)])
ATO_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ATO_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ATO_30min.txt")
display(ATO_30min_spark_DF)

ATVI_30min_spark_DF_newRow = StructType([StructField("ATVI_date/time", StringType(), True),StructField("ATVI_adjOpen", FloatType(), True),StructField("ATVI_adjHigh", FloatType(), True),StructField("ATVI_adjLow", FloatType(), True),StructField("ATVI_adjClose", FloatType(), True),StructField("ATVI_adjVolume", IntegerType(), True)])
ATVI_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(ATVI_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/ATVI_30min.txt")
display(ATVI_30min_spark_DF)

AVB_30min_spark_DF_newRow = StructType([StructField("AVB_date/time", StringType(), True),StructField("AVB_adjOpen", FloatType(), True),StructField("AVB_adjHigh", FloatType(), True),StructField("AVB_adjLow", FloatType(), True),StructField("AVB_adjClose", FloatType(), True),StructField("AVB_adjVolume", IntegerType(), True)])
AVB_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AVB_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AVB_30min.txt")
display(AVB_30min_spark_DF)

AVGO_30min_spark_DF_newRow = StructType([StructField("AVGO_date/time", StringType(), True),StructField("AVGO_adjOpen", FloatType(), True),StructField("AVGO_adjHigh", FloatType(), True),StructField("AVGO_adjLow", FloatType(), True),StructField("AVGO_adjClose", FloatType(), True),StructField("AVGO_adjVolume", IntegerType(), True)])
AVGO_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AVGO_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AVGO_30min.txt")
display(AVGO_30min_spark_DF)

AVY_30min_spark_DF_newRow = StructType([StructField("AVY_date/time", StringType(), True),StructField("AVY_adjOpen", FloatType(), True),StructField("AVY_adjHigh", FloatType(), True),StructField("AVY_adjLow", FloatType(), True),StructField("AVY_adjClose", FloatType(), True),StructField("AVY_adjVolume", IntegerType(), True)])
AVY_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AVY_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AVY_30min.txt")
display(AVY_30min_spark_DF)

AWK_30min_spark_DF_newRow = StructType([StructField("AWK_date/time", StringType(), True),StructField("AWK_adjOpen", FloatType(), True),StructField("AWK_adjHigh", FloatType(), True),StructField("AWK_adjLow", FloatType(), True),StructField("AWK_adjClose", FloatType(), True),StructField("AWK_adjVolume", IntegerType(), True)])
AWK_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AWK_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AWK_30min.txt")
display(AWK_30min_spark_DF)

AXP_30min_spark_DF_newRow = StructType([StructField("AXP_date/time", StringType(), True),StructField("AXP_adjOpen", FloatType(), True),StructField("AXP_adjHigh", FloatType(), True),StructField("AXP_adjLow", FloatType(), True),StructField("AXP_adjClose", FloatType(), True),StructField("AXP_adjVolume", IntegerType(), True)])
AXP_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AXP_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AXP_30min.txt")
display(AXP_30min_spark_DF)

AYI_30min_spark_DF_newRow = StructType([StructField("AYI_date/time", StringType(), True),StructField("AYI_adjOpen", FloatType(), True),StructField("AYI_adjHigh", FloatType(), True),StructField("AYI_adjLow", FloatType(), True),StructField("AYI_adjClose", FloatType(), True),StructField("AYI_adjVolume", IntegerType(), True)])
AYI_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AYI_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AYI_30min.txt")
display(AYI_30min_spark_DF)

AZO_30min_spark_DF_newRow = StructType([StructField("AZO_date/time", StringType(), True),StructField("AZO_adjOpen", FloatType(), True),StructField("AZO_adjHigh", FloatType(), True),StructField("AZO_adjLow", FloatType(), True),StructField("AZO_adjClose", FloatType(), True),StructField("AZO_adjVolume", IntegerType(), True)])
AZO_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(AZO_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/AZO_30min.txt")
display(AZO_30min_spark_DF)

A_30min_spark_DF_newRow = StructType([StructField("A_date/time", StringType(), True),StructField("A_adjOpen", FloatType(), True),StructField("A_adjHigh", FloatType(), True),StructField("A_adjLow", FloatType(), True),StructField("A_adjClose", FloatType(), True),StructField("A_adjVolume", IntegerType(), True)])
A_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(A_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/A_30min.txt")
display(A_30min_spark_DF)


# COMMAND ----------

BAC_30min_spark_DF_newRow = StructType([StructField("BAC_date/time", StringType(), True),StructField("BAC_adjOpen", FloatType(), True),StructField("BAC_adjHigh", FloatType(), True),StructField("BAC_adjLow", FloatType(), True),StructField("BAC_adjClose", FloatType(), True),StructField("BAC_adjVolume", IntegerType(), True)])
BAC_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(BAC_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/BAC_30min.txt")
display(BAC_30min_spark_DF)

BAX_30min_spark_DF_newRow = StructType([StructField("BAX_date/time", StringType(), True),StructField("BAX_adjOpen", FloatType(), True),StructField("BAX_adjHigh", FloatType(), True),StructField("BAX_adjLow", FloatType(), True),StructField("BAX_adjClose", FloatType(), True),StructField("BAX_adjVolume", IntegerType(), True)])
BAX_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(BAX_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/BAX_30min.txt")
display(BAX_30min_spark_DF)

BA_30min_spark_DF_newRow = StructType([StructField("BA_date/time", StringType(), True),StructField("BA_adjOpen", FloatType(), True),StructField("BA_adjHigh", FloatType(), True),StructField("BA_adjLow", FloatType(), True),StructField("BA_adjClose", FloatType(), True),StructField("BA_adjVolume", IntegerType(), True)])
BA_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(BA_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/BA_30min.txt")
display(BA_30min_spark_DF)

BBBY_30min_spark_DF_newRow = StructType([StructField("BBBY_date/time", StringType(), True),StructField("BBBY_adjOpen", FloatType(), True),StructField("BBBY_adjHigh", FloatType(), True),StructField("BBBY_adjLow", FloatType(), True),StructField("BBBY_adjClose", FloatType(), True),StructField("BBBY_adjVolume", IntegerType(), True)])
BBBY_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(BBBY_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/BBBY_30min.txt")
display(BBBY_30min_spark_DF)

BBY_30min_spark_DF_newRow = StructType([StructField("BBY_date/time", StringType(), True),StructField("BBY_adjOpen", FloatType(), True),StructField("BBY_adjHigh", FloatType(), True),StructField("BBY_adjLow", FloatType(), True),StructField("BBY_adjClose", FloatType(), True),StructField("BBY_adjVolume", IntegerType(), True)])
BBY_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(BBY_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/BBY_30min.txt")
display(BBY_30min_spark_DF)

BC_30min_spark_DF_newRow = StructType([StructField("BC_date/time", StringType(), True),StructField("BC_adjOpen", FloatType(), True),StructField("BC_adjHigh", FloatType(), True),StructField("BC_adjLow", FloatType(), True),StructField("BC_adjClose", FloatType(), True),StructField("BC_adjVolume", IntegerType(), True)])
BC_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(BC_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/BC_30min.txt")
display(BC_30min_spark_DF)

BDX_30min_spark_DF_newRow = StructType([StructField("BDX_date/time", StringType(), True),StructField("BDX_adjOpen", FloatType(), True),StructField("BDX_adjHigh", FloatType(), True),StructField("BDX_adjLow", FloatType(), True),StructField("BDX_adjClose", FloatType(), True),StructField("BDX_adjVolume", IntegerType(), True)])
BDX_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(BDX_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/BDX_30min.txt")
display(BDX_30min_spark_DF)

BEN_30min_spark_DF_newRow = StructType([StructField("BEN_date/time", StringType(), True),StructField("BEN_adjOpen", FloatType(), True),StructField("BEN_adjHigh", FloatType(), True),StructField("BEN_adjLow", FloatType(), True),StructField("BEN_adjClose", FloatType(), True),StructField("BEN_adjVolume", IntegerType(), True)])
BEN_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(BEN_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/BEN_30min.txt")
display(BEN_30min_spark_DF)

BF_B_30min_spark_DF_newRow = StructType([StructField("BF_B_date/time", StringType(), True),StructField("BF_B_adjOpen", FloatType(), True),StructField("BF_B_adjHigh", FloatType(), True),StructField("BF_B_adjLow", FloatType(), True),StructField("BF_B_adjClose", FloatType(), True),StructField("BF_B_adjVolume", IntegerType(), True)])
BF_B_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(BF_B_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/BF_B_30min.txt")
display(BF_B_30min_spark_DF)

BIDU_30min_spark_DF_newRow = StructType([StructField("BIDU_date/time", StringType(), True),StructField("BIDU_adjOpen", FloatType(), True),StructField("BIDU_adjHigh", FloatType(), True),StructField("BIDU_adjLow", FloatType(), True),StructField("BIDU_adjClose", FloatType(), True),StructField("BIDU_adjVolume", IntegerType(), True)])
BIDU_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(BIDU_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/BIDU_30min.txt")
display(BIDU_30min_spark_DF)

BIG_30min_spark_DF_newRow = StructType([StructField("BIG_date/time", StringType(), True),StructField("BIG_adjOpen", FloatType(), True),StructField("BIG_adjHigh", FloatType(), True),StructField("BIG_adjLow", FloatType(), True),StructField("BIG_adjClose", FloatType(), True),StructField("BIG_adjVolume", IntegerType(), True)])
BIG_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(BIG_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/BIG_30min.txt")
display(BIG_30min_spark_DF)

BIIB_30min_spark_DF_newRow = StructType([StructField("BIIB_date/time", StringType(), True),StructField("BIIB_adjOpen", FloatType(), True),StructField("BIIB_adjHigh", FloatType(), True),StructField("BIIB_adjLow", FloatType(), True),StructField("BIIB_adjClose", FloatType(), True),StructField("BIIB_adjVolume", IntegerType(), True)])
BIIB_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(BIIB_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/BIIB_30min.txt")
display(BIIB_30min_spark_DF)

BIO_30min_spark_DF_newRow = StructType([StructField("BIO_date/time", StringType(), True),StructField("BIO_adjOpen", FloatType(), True),StructField("BIO_adjHigh", FloatType(), True),StructField("BIO_adjLow", FloatType(), True),StructField("BIO_adjClose", FloatType(), True),StructField("BIO_adjVolume", IntegerType(), True)])
BIO_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(BIO_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/BIO_30min.txt")
display(BIO_30min_spark_DF)

BKNG_30min_spark_DF_newRow = StructType([StructField("BKNG_date/time", StringType(), True),StructField("BKNG_adjOpen", FloatType(), True),StructField("BKNG_adjHigh", FloatType(), True),StructField("BKNG_adjLow", FloatType(), True),StructField("BKNG_adjClose", FloatType(), True),StructField("BKNG_adjVolume", IntegerType(), True)])
BKNG_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(BKNG_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/BKNG_30min.txt")
display(BKNG_30min_spark_DF)

BK_30min_spark_DF_newRow = StructType([StructField("BK_date/time", StringType(), True),StructField("BK_adjOpen", FloatType(), True),StructField("BK_adjHigh", FloatType(), True),StructField("BK_adjLow", FloatType(), True),StructField("BK_adjClose", FloatType(), True),StructField("BK_adjVolume", IntegerType(), True)])
BK_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(BK_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/BK_30min.txt")
display(BK_30min_spark_DF)

BLK_30min_spark_DF_newRow = StructType([StructField("BLK_date/time", StringType(), True),StructField("BLK_adjOpen", FloatType(), True),StructField("BLK_adjHigh", FloatType(), True),StructField("BLK_adjLow", FloatType(), True),StructField("BLK_adjClose", FloatType(), True),StructField("BLK_adjVolume", IntegerType(), True)])
BLK_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(BLK_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/BLK_30min.txt")
display(BLK_30min_spark_DF)

BLL_30min_spark_DF_newRow = StructType([StructField("BLL_date/time", StringType(), True),StructField("BLL_adjOpen", FloatType(), True),StructField("BLL_adjHigh", FloatType(), True),StructField("BLL_adjLow", FloatType(), True),StructField("BLL_adjClose", FloatType(), True),StructField("BLL_adjVolume", IntegerType(), True)])
BLL_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(BLL_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/BLL_30min.txt")
display(BLL_30min_spark_DF)

BMRN_30min_spark_DF_newRow = StructType([StructField("BMRN_date/time", StringType(), True),StructField("BMRN_adjOpen", FloatType(), True),StructField("BMRN_adjHigh", FloatType(), True),StructField("BMRN_adjLow", FloatType(), True),StructField("BMRN_adjClose", FloatType(), True),StructField("BMRN_adjVolume", IntegerType(), True)])
BMRN_30min_spark_DF = spark.read.format("csv").option("header", "false").schema(BMRN_30min_spark_DF_newRow).load("/FileStore/tables/FirstRate30mins/BMRN_30min.txt")
display(BMRN_30min_spark_DF)

BMY_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/BMY_30min.txt", header="true", inferSchema="true")
BRK_B_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/BRK_B_30min.txt", header="true", inferSchema="true")
BRO_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/BRO_30min.txt", header="true", inferSchema="true")
BR_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/BR_30min.txt", header="true", inferSchema="true")
BSX_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/BSX_30min.txt", header="true", inferSchema="true")
BTU_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/BTU_30min.txt", header="true", inferSchema="true")
BUD_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/BUD_30min.txt", header="true", inferSchema="true")
BWA_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/BWA_30min.txt", header="true", inferSchema="true")
BXP_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/BXP_30min.txt", header="true", inferSchema="true")


# COMMAND ----------

BAC_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CAG_30min.txt", header="true", inferSchema="true")
BAX_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CAH_30min.txt", header="true", inferSchema="true")
BA_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CARR_30min.txt", header="true", inferSchema="true")
BBBY_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CAR_30min.txt", header="true", inferSchema="true")
BBY_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CAT_30min.txt", header="true", inferSchema="true")
BC_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CBH_30min.txt", header="true", inferSchema="true")
BDX_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CBOE_30min.txt", header="true", inferSchema="true")
BEN_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CBRE_30min.txt", header="true", inferSchema="true")
BF_B_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CB_30min.txt", header="true", inferSchema="true")
BIDU_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CCI_30min.txt", header="true", inferSchema="true")
BIG_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CCK_30min.txt", header="true", inferSchema="true")
BIIB_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CCL_30min.txt", header="true", inferSchema="true")
BIO_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CCU_30min.txt", header="true", inferSchema="true")
BKNG_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CC_30min.txt", header="true", inferSchema="true")
BK_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CDAY_30min.txt", header="true", inferSchema="true")
BLK_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CDNS_30min.txt", header="true", inferSchema="true")
BLL_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CDW_30min.txt", header="true", inferSchema="true")
BMRN_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CERN_30min.txt", header="true", inferSchema="true")
BMY_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CE_30min.txt", header="true", inferSchema="true")
BRK_B_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CFG_30min.txt", header="true", inferSchema="true")
BRO_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CF_30min.txt", header="true", inferSchema="true")
BR_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CHD_30min.txt", header="true", inferSchema="true")
BSX_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CHIR_30min.txt", header="true", inferSchema="true")
BTU_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CHKP_30min.txt", header="true", inferSchema="true")
BUD_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CHK_30min.txt", header="true", inferSchema="true")
BWA_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CHRW_30min.txt", header="true", inferSchema="true")
BXP_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CHTR_30min.txt", header="true", inferSchema="true")

BAC_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CIEN_30min.txt", header="true", inferSchema="true")
BAX_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CINF_30min.txt", header="true", inferSchema="true")
BA_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CIT_30min.txt", header="true", inferSchema="true")
BBBY_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CI_30min.txt", header="true", inferSchema="true")
BBY_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CLF_30min.txt", header="true", inferSchema="true")
BC_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CLX_30min.txt", header="true", inferSchema="true")
BDX_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CL_30min.txt", header="true", inferSchema="true")
BEN_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CMA_30min.txt", header="true", inferSchema="true")
BF_B_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CMCSA_30min.txt", header="true", inferSchema="true")
BIDU_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CME_30min.txt", header="true", inferSchema="true")
BIG_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CMG_30min.txt", header="true", inferSchema="true")
BIIB_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CMI_30min.txt", header="true", inferSchema="true")
BIO_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CMS_30min.txt", header="true", inferSchema="true")
BKNG_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CNC_30min.txt", header="true", inferSchema="true")
BK_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CNP_30min.txt", header="true", inferSchema="true")
BLK_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CNX_30min.txt", header="true", inferSchema="true")
BLL_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/COF_30min.txt", header="true", inferSchema="true")
BMRN_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/COOP_30min.txt", header="true", inferSchema="true")
BMY_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/COO_30min.txt", header="true", inferSchema="true")
BRK_B_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/COP_30min.txt", header="true", inferSchema="true")
BRO_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/COST_30min.txt", header="true", inferSchema="true")
BR_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/COTY_30min.txt", header="true", inferSchema="true")
BSX_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CPB_30min.txt", header="true", inferSchema="true")
BTU_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CPRI_30min.txt", header="true", inferSchema="true")
BUD_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CPRT_30min.txt", header="true", inferSchema="true")
BWA_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CRM_30min.txt", header="true", inferSchema="true")
BXP_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CSCO_30min.txt", header="true", inferSchema="true")

BAC_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CSX_30min.txt", header="true", inferSchema="true")
BAX_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CTAS_30min.txt", header="true", inferSchema="true")
BA_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CTLT_30min.txt", header="true", inferSchema="true")
BBBY_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CTSH_30min.txt", header="true", inferSchema="true")
BBY_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CTVA_30min.txt", header="true", inferSchema="true")
BC_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CTXS_30min.txt", header="true", inferSchema="true")
BDX_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CVS_30min.txt", header="true", inferSchema="true")
BEN_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CVX_30min.txt", header="true", inferSchema="true")
BF_B_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/CZR_30min.txt", header="true", inferSchema="true")
BIDU_30min_spark_DF = spark.read.csv("/FileStore/tables/FirstRate30mins/C_30min.txt", header="true", inferSchema="true")